{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcription-from-linguists.txt','r', encoding=\"utf-8\") as f:\n",
    "    contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forPhoneMapping.txt','r', encoding=\"utf-8\") as f:\n",
    "    phone_content_f = f.read()\n",
    "with open('timitIPAtoArpa.txt','r', encoding=\"utf-8\") as f2:\n",
    "    timit_content_f = f2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɪ', 'e', 'ɛ', 'æ', 'a', 'ɒ', 'o', 'u', \"ɚ'\", 'ə', 'au', 'ai', 'ŋ', 'r', 'ɡ', 'ɨ', 'y', 'ð', 'd', 'i', 'n', 'ɔ', 't', 'h', 'w', 'f', 'l', 'm', 'b', 's', 'k', 'p', 'z', 'dʒ', 'ʒ', 'θ', 'v', 'ʃ', 'j', 't̪', 'ɖ', 'ʈ', 'tʃ', 'ɔe', 'd̪', 'i:', 'ʈʃ', 'u:', 'ei', 'eə', 'iə', 'e:', 'ao', 'ɔi', 'c', 'ae', 'ɽ', 'a:', 'a˞', 'o:', 'q', 'ui', 'wh', 'kh', 'ʈh', 't̪h', 'd̪h', 'gh', 'ph', 'bh', 'ɭ', 'oə', 'uə', 'ɔɪ', 'əu', 'ia', 'əi', 'əo', 'io', 'ie', 'dⁿ', 'ɳ', 'd̺', 'ʐ', 'ɹ']\n",
      "\n",
      "\n",
      "\n",
      "['IH', 'IH', 'EH', 'AE', 'AA', 'AO', 'UH', 'UW', 'AXR', 'AX', 'AW', 'AY', 'NG', 'R', 'G', 'IX', 'IY', 'DH', 'D', 'IY', 'N', 'AO', 'T', 'HH', 'W', 'F', 'L', 'M', 'B', 'S', 'K', 'P', 'Z', 'JH', 'ZH', 'TH', 'V', 'SH', 'Y', 'T', 'D', 'T', 'CH', 'OY', 'D', 'IH Y', 'CH', 'UW', 'EY', 'EY', 'IH AX', 'EH', 'AW', 'OY', 'CH', 'AE', 'R', 'AA', 'AXR', 'AO', 'K', 'UH IH', 'W HH', 'K HH', 'T HH', 'T HH', 'D HH', 'G HH', 'P HH', 'B HH', 'L', 'AO AX', 'UW AX', 'OY', 'AW', 'IH Y AX', 'AX IY', 'AX UH', 'IY AO', 'IY EH', 'D N', 'N', 'D', 'Z', 'R']\n"
     ]
    }
   ],
   "source": [
    "p_sym=[]\n",
    "timit_sym=[]\n",
    "pattern1f=re.compile(r'(\\S+)\\t(.*)\\t(.*)\\n') \n",
    "pattern2f=re.compile(r'(\\S+)\\t(\\S+)')\n",
    "matches1f=pattern1f.findall(phone_content_f)\n",
    "matches2f=pattern2f.findall(timit_content_f)\n",
    "\n",
    "iter_matches1f=pattern1f.finditer(phone_content_f)\n",
    "iter_matches2f=pattern2f.finditer(timit_content_f)\n",
    "match1col1=[]\n",
    "match1col2=[]\n",
    "match2col1=[]\n",
    "match2col2=[]\n",
    "for i in iter_matches1f:\n",
    "    #print(i.group(1))\n",
    "    match1col1.append(i.group(1)) #1st and 3rd column in file forphonemapping\n",
    "    match1col2.append(i.group(3))\n",
    "for i in iter_matches2f:\n",
    "    match2col1.append(i.group(1))\n",
    "    match2col2.append(i.group(2)) #1st and 2nd column in timitIPAtoARPA\n",
    "print(match1col1)\n",
    "print(\"\\n\\n\")\n",
    "print(match1col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ɪ': 'IH', 'e': 'IH', 'ɛ': 'EH', 'æ': 'AE', 'a': 'AA', 'ɒ': 'AO', 'o': 'UH', 'u': 'UW', \"ɚ'\": 'AXR', 'ə': 'AX', 'au': 'AW', 'ai': 'AY', 'ŋ': 'NG', 'r': 'R', 'ɡ': 'G', 'ɨ': 'IX', 'y': 'IY', 'ð': 'DH', 'd': 'D', 'i': 'IY', 'n': 'N', 'ɔ': 'AO', 't': 'T', 'h': 'HH', 'w': 'W', 'f': 'F', 'l': 'L', 'm': 'M', 'b': 'B', 's': 'S', 'k': 'K', 'p': 'P', 'z': 'Z', 'dʒ': 'JH', 'ʒ': 'ZH', 'θ': 'TH', 'v': 'V', 'ʃ': 'SH', 'j': 'Y', 't̪': 'T', 'ɖ': 'D', 'ʈ': 'T', 'tʃ': 'CH', 'ɔe': 'OY', 'd̪': 'D', 'i:': 'IH Y', 'ʈʃ': 'CH', 'u:': 'UW', 'ei': 'EY', 'eə': 'EY', 'iə': 'IH AX', 'e:': 'EH', 'ao': 'AW', 'ɔi': 'OY', 'c': 'CH', 'ae': 'AE', 'ɽ': 'R', 'a:': 'AA', 'a˞': 'AXR', 'o:': 'AO', 'q': 'K', 'ui': 'UH IH', 'wh': 'W HH', 'kh': 'K HH', 'ʈh': 'T HH', 't̪h': 'T HH', 'd̪h': 'D HH', 'gh': 'G HH', 'ph': 'P HH', 'bh': 'B HH', 'ɭ': 'L', 'oə': 'AO AX', 'uə': 'UW AX', 'ɔɪ': 'OY', 'əu': 'AW', 'ia': 'IH Y AX', 'əi': 'AX IY', 'əo': 'AX UH', 'io': 'IY AO', 'ie': 'IY EH', 'dⁿ': 'D N', 'ɳ': 'N', 'd̺': 'D', 'ʐ': 'Z', 'ɹ': 'R'}\n",
      "\n",
      "\n",
      "\n",
      "{'b': 'b', 'd': 'd', 'ɡ': 'g', 'p': 'p', 't': 't', 'k': 'k', 'ɾ': 'dx', 'ʔ': 'q', 'dʒ': 'jh', 'tʃ': 'ch', 's': 's', 'ʃ': 'sh', 'z': 'z', 'ʒ': 'zh', 'f': 'f', 'θ': 'th', 'v': 'v', 'ð': 'dh', 'm': 'm', 'n': 'n', 'm̩': 'em', 'ŋ': 'ng', 'n̩': 'en', 'ŋ̍': 'eng', 'ɾ̃': 'nx', 'l': 'l', 'l̩': 'el', 'r': 'r', 'w': 'w', 'j': 'y', 'h': 'hh', 'ɦ': 'hv', 'i': 'iy', 'ɪ': 'ih', 'ɛ': 'eh', 'eɪ': 'ey', 'æ': 'ae', 'ɑ': 'aa', 'aʊ': 'aw', 'aɪ': 'ay', 'ʌ': 'ah', 'ɔ': 'ao', 'ɔi': 'oy', 'oʊ': 'ow', 'ʊ': 'uh', 'u': 'uw', 'ʉ': 'ux', 'ɝ': 'er', 'ə': 'ax', 'ᵻ': 'ix', 'ɚ': 'axr', 'ə̥': 'ax-h', 'd̚': 'dcl', 'b̚': 'bcl', 'ɡ̚': 'gcl', 'k̚': 'kcl', 'p̚': 'pcl', 't̚': 'tcl'}\n"
     ]
    }
   ],
   "source": [
    "phone_dict={}\n",
    "timit_dict={}\n",
    "for i in range(len(match1col1)):\n",
    "    phone_dict[match1col1[i]]=match1col2[i]\n",
    "for i in range(len(match2col1)):\n",
    "    timit_dict[match2col1[i]]=match2col2[i]\n",
    "print(phone_dict)\n",
    "print(\"\\n\\n\")\n",
    "print(timit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamps=[]\n",
    "word_lines=[]\n",
    "check_phone=[]\n",
    "file_name=[]\n",
    "pattern_test2=re.compile(r',(\\d\\d/\\d\\d/201[78] \\d\\d:\\d\\d:\\d\\d),(file_\\d\\d\\d\\d\\.wav),(.*)\\b(\\?,|\\?\\.,|!\\.,|\\.,|\\.\\.,|\\)\\.,){1}(.*)(\\?|\\!|\\.|,\\))*\\n?')\n",
    "#pattern_test2=re.compile(r'(file_\\d\\d\\d\\d\\.wav),(.*)\\b\\)?\\.,(.*)[\\?\\!\\.\\,)]?\\n?')\n",
    "matches_test2=pattern_test2.finditer(contents)\n",
    "#matches_test3=pattern_test3.finditer(contents)\n",
    "#print(matches_test2)\n",
    "for i in matches_test2: #extracting time stamps, file names, english sentence, phonetic symbols by mattching regex pattern\n",
    "    time_stamps.append(i.group(1))\n",
    "    file_name.append(i.group(2))\n",
    "    word_lines.append(i.group(3))\n",
    "    check_phone.append(i.group(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect=[]\n",
    "for stri in check_phone:\n",
    "    pat_=re.compile(r'[^\\s\\d_~]{2,3}')#(r'\\S{2,3}') #match symbols with two or 3 characters like i: / t̪ / d̪h (counted as 3 chars)\n",
    "    pat2_=re.compile(r'[^\\s\\d_~]')#(r'\\S{1}')\n",
    "    stri=stri.replace('.','')\n",
    "    stri=re.sub(r'~[ ]?--[ ]?~',' ~', stri)\n",
    "    stri=re.sub(r'[ ]?-[ ]?', ' ', stri)\n",
    "    stri=re.sub(r': ?', ': ', stri) #to avoid problems in processing i:n or i:? by providing space after colon\n",
    "    mat_=pat_.findall(stri)\n",
    "    mat2_=pat2_.findall(stri)\n",
    "    for i in mat_:\n",
    " #   print(i)\n",
    "        if i in phone_dict:\n",
    "            stri=stri.replace(i, phone_dict[i])\n",
    "        elif i in timit_dict:\n",
    "            stri=stri.replace(i, timit_dict[i])\n",
    "        \n",
    "#print(\"\\n\\n\")\n",
    "    for j in mat2_:\n",
    "        if j in phone_dict:\n",
    "  #      print(j,phone_dict[j])\n",
    "            stri=stri.replace(j, phone_dict[j])\n",
    "        elif j in timit_dict:\n",
    "            stri=stri.replace(j,timit_dict[j])\n",
    "    collect.append(stri.lower())\n",
    "#print(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927\n"
     ]
    }
   ],
   "source": [
    "print(len(collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baetshihs\n",
      "iyt~waxz~aokwaxd~vihriy~aokwaxd\n",
      "naaihbaxr\n"
     ]
    }
   ],
   "source": [
    "for i in collect: #This was to only check set of lines where symbols were without any space and converted as such.This block has no use.\n",
    "    blip=i\n",
    "    #match = re.search(r'^\\S+\\b(\\.|\\?)?$', i) #re.MULTILINE) #re.DOTALL)\n",
    "    #print(match)\n",
    "    p=re.compile(r'^\\S+\\b\\s?[\\.\\?\\!]?$') #(r'^\\S+\\b(\\.|\\?)?$')\n",
    "    m=p.finditer(blip)\n",
    "    for j in m:\n",
    "        #i=re.sub('[~]', ' ~ ', i)\n",
    "        print(j.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('myphones.64-48-40.map','r', encoding=\"utf-8\") as f:\n",
    "    myphones = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aa': 'aa', 'ae': 'ae', 'ah': 'ah', 'ao': 'ao', 'aw': 'aw', 'ax': 'ah', 'ax-h': 'ah', 'axr': 'er', 'ay': 'ay', 'b': 'b', 'bcl': 'sil', 'ch': 'ch', 'd': 'd', 'dcl': 'sil', 'dh': 'dh', 'dx': 'dh', 'ea': 'eh', 'eh': 'eh', 'el': 'l', 'em': 'm', 'en': 'n', 'eng': 'ng', 'epi': 'sil', 'er': 'er', 'ey': 'ey', 'f': 'f', 'g': 'g', 'gcl': 'sil', 'h#': 'sil', 'hh': 'hh', 'hv': 'hh', 'ia': 'ih', 'ih': 'ih', 'ix': 'ih', 'iy': 'iy', 'jh': 'jh', 'k': 'k', 'kcl': 'sil', 'l': 'l', 'm': 'm', 'n': 'n', 'ng': 'ng', 'nx': 'n', 'oh': 'ah', 'ow': 'ow', 'oy': 'oy', 'p': 'p', 'pau': 'sil', 'pcl': 'sil', 'r': 'r', 's': 's', 'sh': 'sh', 't': 't', 'tcl': 'sil', 'th': 'th', 'ua': 'uh', 'uh': 'uh', 'uw': 'uw', 'ux': 'uw', 'v': 'v', 'w': 'w', 'y': 'y', 'z': 'z'}\n"
     ]
    }
   ],
   "source": [
    "mp_col1=[]\n",
    "mp_col2=[]\n",
    "mp_dict={}\n",
    "mp_pat=re.compile(r'(\\S+)\\t(\\S+)\\t(\\S+)\\n') \n",
    "mp_matches=mp_pat.finditer(myphones)\n",
    "for i in mp_matches:\n",
    "    mp_col1.append(i.group(1))\n",
    "    mp_col2.append(i.group(3))\n",
    "for i in range(len(mp_col1)):\n",
    "    mp_dict[mp_col1[i]]=mp_col2[i] #myphones.64-48-40 dictionary\n",
    "print(mp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=[]\n",
    "for i in collect:\n",
    "    mep=i\n",
    "    mep=re.sub('[()]', '', mep)\n",
    "    #mep=re.sub('[(]', ' ', mep)\n",
    "    #mep=re.sub('[)]', ' ', mep)\n",
    "    mep=re.sub(r'\\?*!*,*:*;*', '', mep) #all punctuation characters to be replaced by nothing.\n",
    "    #mep=re.sub('[?]', '', mep)\n",
    "    #mep=re.sub('[!]', '', mep)\n",
    "    #mep=re.sub('[,]', '', mep)\n",
    "    #mep=re.sub('[:]', '', mep)\n",
    "    #mep=re.sub('[;]', '', mep)\n",
    "    mep=mep.replace(\"'\",\"\")\n",
    "    #mep=re.sub(r'~[ ]?--[ ]?~',' ~', mep)\n",
    "    #mep=re.sub(r'[ ]?-[ ]?', ' ', mep)\n",
    "    pat_fin=re.compile(r'[^\\s\\d_~]{2,3}')#(r'[^~]?\\S+[^~]?')\n",
    "    #pat_fin=re.compile(r'[^\\s\\d_~]')\n",
    "    #pat_fin2=re.compile(r'\\s{2}')\n",
    "    #pat_fin3=re.compile(r'\\s{1}')#working=r'\\S+'\n",
    "    mat_fin=pat_fin.findall(mep)\n",
    "    #mat_fin1=\n",
    "    for j in mat_fin:\n",
    "            #print(j)\n",
    "        if j in mp_dict:\n",
    "                #print(j, mp_dict[j])\n",
    "            mep=mep.replace(j,mp_dict[j])\n",
    "            #print(mep)\n",
    "    temp_list.append(mep)\n",
    "                \n",
    "            #print(j[0])\n",
    "    #z+=1\n",
    "#print(temp_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927\n"
     ]
    }
   ],
   "source": [
    "print(len(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlines=[]\n",
    "phonelines=[]\n",
    "for i in word_lines:\n",
    "    test_wordlines=i.replace(\"'\",\"\")\n",
    "    test_wordlines=re.sub(r'\\?*!*,*\\.*;*:*', '', test_wordlines)\n",
    "    test_wordlines=re.sub(r'[ ]?--[ ]?',' ', test_wordlines)\n",
    "    test_wordlines=re.sub(r'[ ]?-[ ]?', ' ', test_wordlines)\n",
    "    test_wordlines=test_wordlines.replace(\"'\",\"\")\n",
    "    wordlines.append(test_wordlines)\n",
    "for i in check_phone:\n",
    "    test_phone=i.replace(\"'\",\"\")\n",
    "    test_phone=re.sub(r'\\?*!*,*\\.*;*', '', test_phone)\n",
    "    test_phone=re.sub(r'~[ ]?--[ ]?~',' ~', test_phone)\n",
    "    test_phone=re.sub(r'[ ]?-[ ]?', ' ', test_phone)\n",
    "    test_phone=test_phone.replace(\"'\",\"\")\n",
    "    phonelines.append(test_phone)\n",
    "#print(phonelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927 2927 2927 2927\n"
     ]
    }
   ],
   "source": [
    "print(len(file_name), len(temp_list), len(wordlines), len(time_stamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927\n",
      "2927\n",
      "2927 2927\n"
     ]
    }
   ],
   "source": [
    "combi=list(zip(file_name,temp_list)) #file name and symbols after processing\n",
    "print(len(combi))\n",
    "combi2=list(zip(file_name, wordlines)) #file name and english sentences\n",
    "print(len(combi2))\n",
    "combi3=list(zip(file_name, time_stamps)) #file name and time stamps\n",
    "combi4=list(zip(file_name, phonelines)) #file name and unprocessed phonetic symbols\n",
    "print(len(combi3), len(combi4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 2442 2442 2442\n"
     ]
    }
   ],
   "source": [
    "test_dicky={} # file name+ processed symbols dictionary\n",
    "test_dicky2={} #file name+ english sentences\n",
    "test_dicky3={} # time stamps+ file name\n",
    "test_dicky4={} #file name+ unprocessed phonetic symbol lines\n",
    "for x,y in combi:\n",
    "    test_dicky[x]=y\n",
    "for x,y in combi2:\n",
    "    test_dicky2[x]=y\n",
    "for x,y in combi3:\n",
    "    test_dicky3[x]=y\n",
    "for x,y in combi4:\n",
    "    test_dicky4[x]=y\n",
    "print(len(test_dicky), len(test_dicky2), len(test_dicky3), len(test_dicky4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927\n"
     ]
    }
   ],
   "source": [
    "print(len(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import OrderedDict\n",
    "#check=list(OrderedDict.fromkeys(test)) #file_name inside initialy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subMapInfo.txt','r', encoding=\"utf-8\") as f:\n",
    "    submapinfo = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submapdict={}\n",
    "intonation=[]\n",
    "submapfile=[]\n",
    "submap_pat=re.compile(r'\\w+ (\\w+_.*) (file_\\d+\\.wav)')\n",
    "submapmatch=submap_pat.finditer(submapinfo)\n",
    "for i in submapmatch:\n",
    "    submapfile.append(i.group(2))\n",
    "    intonation.append(i.group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(submapfile)):\n",
    "    submapdict[submapfile[i]]=intonation[i] #file name with intonation file details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "uniquefilename=list(OrderedDict.fromkeys(file_name))\n",
    "print(len(uniquefilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_str_fin=\"\"\n",
    "into_processed=\"\"\n",
    "check_str_list_fin=[]\n",
    "for i in uniquefilename: #time stamp+ file name+ english sentence+ unprocessed symbol lines+ inonation label+ processeded symbol lines\n",
    "    check_str_fin=check_str_fin+test_dicky3[i]+' '+i+' '+ test_dicky2[i]+' '+test_dicky4[i]+'==>'+submapdict[i]+' '+test_dicky[i]+\"\\n\" #string line containing info\n",
    "    into_processed=into_processed+ submapdict[i]+' '+ test_dicky[i]+\"\\n\" #intonation_l1... processed line\n",
    "    check_str_list_fin.append(check_str_fin) #string line appended to a list, not actively used further. Instead used the string itself.\n",
    "#print(check_str_fin)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "with io.open('checkcheck.txt', 'w', encoding='utf-8') as f: #had an empty text file with this name in a directory already created\n",
    "    f.write(into_processed) #writing into that empty text file with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('checkcheck_2.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(check_str_fin) #writing the whole processed string with all details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
